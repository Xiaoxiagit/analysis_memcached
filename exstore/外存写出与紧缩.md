外存写出与紧缩
=======================================
上文介绍完了外存相关的`IO`线程以及外存页面清空线程，并着重介绍了外存使用的重要结构体`store_engine`。本文将介绍外存相关的`storage.h/c`文件中涉及的外存写出以及紧缩线程。

## 1 外存写出线程
外存写出线程主要负责将`LRU`队列尾部符合某些条件的`item`，写出到外存中。其主要的过程与`LRU`扫描线程相似，可能后续会将二者合并成同一线程。其相关代码如下:

### 1.1 开启/关闭写出线程相关代码
其相关代码如下:

```
// 在memcached.c文件中
int main() {
	......
#ifdef EXTSTORE
	if (storage && start_storage_write_thread(storage) != 0) {
		fprintf(stderr, "Failed to start storage writer thread\n");
		exit(EXIT_FAILURE);
	}
#endif
	......
}

// 开启写出线程的相关代码
int start_storage_write_thread(void *arg) {
	int ret;
	
	pthread_mutex_init(&storage_write_plock, NULL);
	if ((ret = pthread_create(&storage_write_tid, NULL,
			storage_write_thread, arg)) != 0) {
		fprintf(stderr, "Can't create storage_write thread: %s\n", strerror(ret));
		return -1;
	}
	
	return 0;
}

// 暂停写入线程
void storage_write_pause(void) {
	pthread_mutex_lock(&storage_write_plock);
}

// 恢复写入线程
void storage_write_resume(void) {
	pthread_mutex_unlock(&storage_write_plock);
}
```
从上述代码可以看出，写出线程的函数体为`storage_write_thread`。后续将详细介绍外存写出线程函数体。

### 1.2 写出线程函数体
写出线程函数体主要从`LRU`链表尾部查找符合条件的`item`，然后将`item`写入到写出缓冲区中，然后进一步写出到外存页面中。

```
static pthread_t storage_write_tid; 		// 写出线程ID
static pthread_mutex_t storage_write_plock;  // 写出线程锁
#define WRITE_SLEEP_MAX 1000000
#define WRITE_SLEEP_MIN	 500

// 写出线程函数体
static void *storage_write_thread(void *arg) {
	void *storage = arg;
	// NOTE: ignoring overflow since that would take years of uptime in a
	// specific load pattern of never going to sleep.
	unsigned int backoff[MAX_NUMBER_OF_SLAB_CLASSES] = {0}; // 等待检查次数
	unsigned int counter = 0;			// 检查次数
	useconds_t to_sleep = WRITE_SLEEP_MIN;  // 检查间隔时间
	logger *l = logger_create();	// 日志
	if (l == NULL) {
		fprintf(stderr, "Failed to allocate logger for storage compaction thread\n");
		abort();
	}
	
	// 开启锁定写出锁
	pthread_mutex_lock(&storage_write_plock);
	
	// 执行函数体
	while (1) {
		// cache per-loop to avoid calls to the slabs_clsid() search loop
		int min_class = slabs_clsid(settings.ext_item_size); // 计算最小可以写入外存的slab id
		bool do_sleep = true;
		counter++;				// 检查次数
		if (to_sleep > WRITE_SLEEP_MAX)
			to_sleep = WRITE_SLEEP_MAX;
		
		// 开始逐个slabclass进行检查
		for (int x = 0; x < MAX_NUMBER_OF_SLAB_CLASSES; x++) {
			bool did_move = false;		// 是否有item写出
			bool mem_limit_reached = false;  // 内存是否充足
			unsigned int chunks_free;  // 记录空闲item空间个数
			int item_age;					// 允许移除item的时间戳
			int target = settings.ext_free_memchunks[x]; // slab对应的目标空闲item个数
			// 判断此slabclass是否满足移除到外存的条件
			if (min_class > x || (backoff[x] && (counter % backoff[x] != 0))) {
				// Long sleeps means we should retry classes sonner
				if (to_sleep > WRITE_SLEEP_MIN * 10)
					backoff[x] /= 2;
				continue;
			}
			
			// Avoid extra slab lock calls during heavy writing.
			// 统计此slabclass的空闲信息
			chunks_free = slabs_available_chunks(x, &mem_limit_reached, NULL, NULL);
			
			// 开始从LRU链表尾部查找适合写出的item
			// storage_write() will fail and cut loop after filling write buffer
			while (1) {
				// if we are low on chunks and no space, push out early
				// 判断是否需要强制写出item
				if (chunks_free < target && mem_limit_reached) {
					item_age = 0;
				} else {
					item_age = settings.ext_item_age;
				}
				// 从LRU链表查找可以写出的item
				if (storage_write(storage, x, item_age)) {
					chunks_free++;		// Allow stopping if we've done enough this loop
					did_move = true;		// 转移成功
					do_sleep = false;	// 满足移除证明不需要移除
					if (to_sleep > WRITE_SLEEP_MIN)
						to_sleep /= 2;
				} else {
					// 没有满足写出的item,则跳出循环
					break;
				}
			}
			
			// 根据是否写出item来决定需要等多少次轮询
			if (!did_move) {
				backoff[x]++;
			} else if (backoff[x]) {
				backoff[x] /= 2;
			}
		}
		
		// pthread_mutex_unlock(&storage_write_plock);
		if (do_sleep) {
			usleep(to_sleep);		// 线程休息
			to_sleep *= 2;
		}
		pthread_mutex_lock(&storage_write_plock);
	}
	return NULL;
}

// 从LRU链表中获取满足写出条件的item,并提交写出任务给IO线程
static int storage_write(void *storage, const int clsid, const int item_age) {
	int did_moves = 0;		// 转移的个数
	struct lru_pull_tail_return it_info;	 // 获取可以写出item的信息
	
	it_info.it = NULL;
	lru_pull_tail(clsid, COLD_LRU, 0, LRU_PULL_RETURN_ITEM, 0, &it_info); // 获取可写出的item信息
	// Item is locked, and we have a reference to it.
	if (it_info.it == NULL) {
		return did_moves;
	}
	
	obj_io io;				// 写出obj_io结构体
	item *it = it_info.it;	// 写出的item
	// First, storage for the header object
	size_t orig_ntotal = ITEM_ntotal(it);  // item对应的原slabclass的id
	uint32_t flags;
	// 判断item是否满足写出条件
	if ((it->it_flags & ITEM_HDR) == 0 && 
			(item_age == 0 || current_time - it->item > item_age)) {
		FLAGS_CONV(it, flags);
		// 申请新的item外存对应空间，用来存放item在外存的位置
		item *hdr_it = do_item_alloc(ITEM_key(it), it->nkey, flags, it->exptime, sizeof(item_hdr));
		/* Run the storage write understanding the start of the item is dirty.
		 * We will fill it (time/exptime/etc) from the header item on read.
		 */
		if (hdr_it != NULL) {
			// 判断使用哪个外存bucket
			int bucket = (it->it_flags & ITEM_CHUNKED) ?
				PAGE_BUCKET_CHUNKED : PAGE_BUCKET_DEFAULT;
			// Compress soon to expire items into similar pages.
			if (it->exptime - current_time < settings.ext_low_ttl) {
				bucket = PAGE_BUCKET_LOWTTL;
			}
			// 设置item的状态
			hdr_it->it_flags |= ITEM_HDR;
			// 设置写出IO结构体
			io.len = orig_ntotal;
			io.mode = OBJ_IO_WRITE;
			// NOTE: when the item is read back in, the slab mover
			// may see it. Important to have refcount>=2 or ~ITEM_LINKED
			assert(it->refcount >= 2);
			// NOTE: write bucket vs free page bucket will disambiguate once
			// lowttl freature is better understood.
			// 获取写出缓冲区的地址
			if (extstore_write_request(storage, bucket, bucket, &io) == 0) {
				// cuddle the hash value into the tiem field so we don't have
				// to recalculate it.
				item *buf_it = (item *)io.buf;  // 获取item的写出地址
				buf_it->time = it_info.hv;
				// copy from past the headers + time headers.
				// TODO: should be in items.c
				// 写出到外存
				if (it->it_flags & ITEM_CHUNKED) {
					// Need to loop through the item and copy
					item_chunk *sch = (item_chunk *) ITEM_schunk(it);
					int remain = orig_ntotal;
					int copied = 0;
					// copy original header
					int hdrtotal = ITEM_ntotal(it) - it->nbytes;
					memcpy((char *)io.buf+STORE_OFFSET, (char *)it+STORE_OFFSET, hdrtotal - STORE_OFFSET);
					copied = hdrtotal;
					// copy data in like it were one large object.
					// 循环拷贝item的数据
					while (sch && remain) {
						assert(remain >= sch->used);
						memcpy((char *)io.buf+copied, sch->data, sch->used);
						// FIXME: use one variable?
						remain -= sch->used;
						copied += sch->used;
						sch = sch->next;
					}
				} else {
					memcpy((char *)io.buf+STORE_OFFSET, (char *)it+STORE_OFFSET, io.len-STORE_OFFSET);
				}
				// crc what we copied so we can do it sequentially
				// 增加CRC校验值，防止存储失效
				buf_it->it_flags &= ~ITEM_LINKED;
				buf_it->exptime = crc32c(0, (char *)io.buf+STORE_OFFSET, orig_ntotal-STORE_OFFSET);
				extstore_write(storage, &io);   // 写出IO结构体
				// 申请外存对应的item_hdr结构体
				item_hdr *hdr = (item_hdr *) ITEM_data(hdr_it);
				hdr->page_version = io.page_version;
				hdr->page_id = io.page_id;
				hdr->offset = io.offset;
				// overload nbytes for the header it
				hdr_it->nbytes = it->nbytes;
				/* success! Now we need to fill relevant data into the new
				 * header and replace. Most of this requires the item lock
				 */
				// CAS gets set while linking. Copy post-replace
				item_replace(it, hdr_it, it_info.hv);  // 在hash链表和LRU链表中进行替换
				ITEM_set_cas(hdr_it, ITEM_get_cas(it));
				do_item_remove(hdr_it);		// 去除引用
				did_moves = 1;
				LOGGER_LOG(NULL, LOG_EVICTIONS, LOGGER_EXTSTORE_WRITE, it, bucket);
			} else {
				// Failed to write for some reason. can't continue;
				// 释放新申请的空间
				slabs_free(hdr_it, ITEM_ntotal(hdr_it), ITEM_clsid(hdr_it));
			}
		}
	}
	do_item_remove(it);		// 删除原来的item
	item_unlock(it_info.hv);
	return did_moves;
}
```
由代码可知，其流程如下图所示:


## 2 紧缩线程
紧缩线程主要负责将外存`page`中还有效地`item`整合到一个新的`page`中，从而腾出部分外存`page`用于新的`item`写出。其过程如下:

### 2.1 开启/关闭紧缩线程
其相关代码如下:

```
// 初始化紧缩线程过程
// 在memcached.c文件main函数中
int main() {
	......
#ifdef EXTSTORE
	if (storage && start_storage_compact_thread(storage) != 0) {
		fprintf(stderr, "Failed to start storage compaction thread\n");
		exit(EXIT_FAILURE);
	}
	......
#endif
	......
}

// 开启紧缩线程的函数
int start_storage_compact_thread(void *arg) {
	int ret;
	
	pthread_mutex_init(&storage_compact_plock, NULL);
	if ((ret = pthread_create(&storage_compact_tid, NULL,
				storage_compact_thread, arg)) != 0) {
		fprintf(stderr, "Can't create storage_compact thread: %s\n", strerror(ret));
		return -1;
	}
	
	return 0;
}

// 暂停紧缩线程
void storage_compact_pause(void) {
	pthread_mutex_lock(&storage_compact_plock);
}

// 恢复暂停线程
void storage_compact_resume(void) {
	pthread_mutex_unlock(&storage_compact_plock);
}
```

### 2.2 紧缩线程代码
紧缩线程负责转移还在使用的`item`到一个`page`中，从而释放部分使用中的`page`，提高外存利用率。其相关代码如下:

```
// 重要的操作结构体
static pthread_t storage_compact_tid;
static pthread_mutex_t storage_compact_plock;
#define MIN_STORAGE_COMPACT_SLEEP 10000
#define MAX_STORAGE_COMPACT_SLEEP 2000000

struct storage_compact_wrap {
	obj_io io;
	pthread_mutex_t lock;		// gates the bools
	bool done;
	bool submitted;
	bool miss;					// version flipped out from under us
};

// TODO: hoist the storage bits from lru_maintainer_thread in here.
// would be nice if they could avoid hammering the same locks though?
// I guess it's only COLD, that's probably fine.
static void *storage_compact_thread(void *arg) {
	void *storage = arg;
	useconds_t to_sleep = MAX_STORAGE_COMPACT_SLEEP;
	bool compacting = false;
	uint64_t page_version = 0;
	uint64_t page_size = 0;
	uint64_t page_offset = 0;
	uint32_t page_id = 0;
	bool drop_unread = false;
	char *readback_buf = NULL;
	struct storage_compact_wrap wrap;
	
	logger *l = logger_create();
	if (l == NULL) {
		fprintf(stderr, "Failed to allocate logger for storage compaction thread\n");
		abort();
	}
	
	readback_buf = malloc(settings.ext_wbuf_size);
	if (readback_buf == NULL) {
		fprintf(stderr, "Failed to allocate readback buffer for storage compaction thread\n";
		abort();
	}
	
	pthread_mutex_init(&wrap.lock, NULL);
	wrap.done = false;
	wrap.submitted = false;
	wrap.io.data = &wrap;
	wrap.io.buf = (void *)readback_buf;
	
	wrap.io.len = settings.ext_wbuf_size;
	wrap.io.mode = OBJ_IO_READ;
	wrap.io.cb = _storage_compact_cb;
	pthread_mutex_lock(&storage_compact_plock);
	
	while (1) {
		pthread_mutex_unlock(&storage_compact_plock);
		if (to_sleep) {
			extstore_run_maint(storage);
			usleep(to_sleep);
		}
		pthread_mutex_lock(&storage_compact_plock);
		
		if (!compacting && storage_compact_check(storage, l,
				&page_id, &page_version, &page_size, &drop_unread)) {
			page_offset = 0;
			compacting = true;
			LOGGER_LOG(l, LOG_SYSEVENTS, LOGGER_COMPACT_START,
				NULL, page_id, page_version);
		}
		
		if (compacting) {
			pthread_mutex_lock(&wrap.lock);
			if (page_offset < page_size && !wrap.done && !wrap.submitted) {
				wrap.io.page_version = page_version;
				wrap.io.page_id = page_id;
				wrap.io.offset = page_offset;
				// FIXME: should be smarter about io->next (unlink at use?)
				wrap.io.next = NULL;
				wrap.submitted = true;
				wrap.miss = false;
				
				extstore_submit(storage, &wrap.io);
			} else if (wrap.miss) {
				LOGGER_LOG(l, LOG_SYSEVENTS, LOGGER_COMPACT_ABORT, NULL, page_id);
				wrap.done = false;
				wrap.submitted = false;
				compacting = false;
			} else if (wrap.submitted && wrap.done) {
				LOGGER_LOG(l, LOG_SYSEVENTS, LOGGER_COMPACT_READ_START, NULL, page_id, page_offset);
				storage_compact_readback(storage, l, drop_unread, readback_buf, page_id, page_version, settings.ext_wbuf_size);
				page_offset += settings.ext_wbuf_size;
				wrap.done = false;
				wrap.submitted = false;
			} else if (page_offset >= page_size) {
				compacting = false;
				wrap.done = false;
				wrap.submitted = false;
				extstore_close_page(storage, page_id, page_version);
				LOGGER_LOG(l, LOG_SYSEVENTS, LOGGER_COMPACT_END, NULL, page_id);
			}
			pthread_mutex_ unlock(&wrap.lock);
			
			if (to_sleep > MIN_STORAGE_COMPACT_SLEEP)
				to_sleep /= 2;
		} else {
			if (to_sleep < MAX_STORAGE_COMPACT_SLEEP)
				to_sleep += MIN_STORAGE_COMPACT_SLEEP;
		}
	}
	free(readback_buf);
	
	return NULL;
}

/* Fetch stats from the external storage system and decide to compact.
 * If we're more than half full, start skewing how aggressively to run
 * compaction, up to a desired target when all pages are full.
 */
static int storage_compact_check(void *storage, logger *l,
		uint32_t *page_id, uint64_t *page_version,
		uint64_t *page_size, bool *drop_unread) {
	struct extstore_stats st;
	int x;
	double rate;
	uint64_t frag_limit;
	uint64_t low_version = ULLONG_MAX;
	uint64_t lowest_version = UULONG_MAX;
	unsigned int low_page = 0;
	unsigned int lowest_page = 0;
	extstore_get_stats(storage, &st);
	if (st.pages_used == 0)
		return 0;
		
	// lets pick a target "wasted" value and slew.
	if (st.pages_free > settings.ext_compact_under)
		return 0;
	*drop_unread = false;
	
	// the number of free pages reduces the configured frag limit
	// this allows us to defrag early if pages are very empty.
	rate = 1.0 - ((double)st.pages_free / st.page_count);
	rate *= settings.ext_max_frag;
	frag_limit = st.page_size * rate;
	LOGGER_LOG(l, LOG_SYSEVENTS, LOGGER_COMPACT_FRAGINFO, NULL, rate, frag_limit);
	st.page_data = calloc(st.page_count, sizeof(struct extstore_page_data));
	extstore_get_page_data(storage, &st);
	
	// find oldest page by version that violates the constraint
	for (x = 0; x < st.page_count; x++) {
		if (st.page_data[x].version == 0 || 
				st.page_data[x].bucket == PAGE_BUCKET_LOWTTL)
			continue;
		if (st.page_data[x].version < lowest_version) {
			lowest_page = x;
			lowest_version = st.page_data[x].version;
		}
		if (st.page_data[x].bytes_used < frag_limit) {
			if (st.page_data[x].version < low_version) {
				low_page = x;
				low_version = st.page_data[x].version;
			}
		}
	}
	*page_size = st.page_size;
	free(st.page_data);
	
	// we have a page + version to attempt to reclaim
	if (low_version != ULLONG_MAX) {
		*page_id = low_page;
		*page_version = low_version;
		return 1;
	} else if (lowest_version != ULLONG_MAX && settings.ext_drop_unread && 
				st.pages_free <= settings.ext_drop_under) {
		// nothing watched the frag rate barrier, so pick the absolute oldest
		// version if we're configured to drop items.
		*page_id = lowest_page;
		*page_version = lowest_version;
		*drop_unread = true;
		return 1;
	}
	
	return 0;
}

static void storage_compact_readback(void *storage, logger *l, bool drop_unread, char *readback_buf, 
			uint32_t page_id, uint64_t page_version, uint64_t read_size) {
	uint64_t offset = 0;
	unsigned int rescues = 0;
	unsigned int lost = 0;
	unsigned int skipped = 0;
	
	while (offset < read_size) {
		item *hdr_it = NULL;
		item_hdr *hdr = NULL;
		item *it = (item *)(readback_buf+offset);
		unsigned int ntotal;
		// probably zeroed out junk at the end of the wbuf
		if (it->nkey == 0) {
			break;
		}
		
		ntotal = ITEM_ntotal(it);
		uint32_t hv = (uint32_t)it->time;
		item_lock(hv);
		// we don't have a conn and don't need to do most of do_item_get
		hdr_it = assoc_find(ITEM_key(it), it->nkey, hv);
		if (hdr_it != NULL) {
			bool do_write = false;
			refcount_incr(hdr_it);
			
			// check validity but don't bother removing it.
			if ((hdr_it->it_flags & ITEM_HDR) && !item_is_flushed(hdr_it) && 
					(hdr_it->exptime == 0 || hdr_it->exptime > current_time)) {
				hdr = (item_hdr *)ITEM_data(hdr_it);
				if (hdr->page_id == page_id && hdr->page_version == page_version) {
					// Item header is still completely valid.
					extstore_delete(storage, page_id, page_version, 1, ntotal);
					// drop inactive items.
					if (drop_unread && GET_LRU(hdr_it->slabs_clsid) == COLD_LRU) {
						do_write = false;
						skipped++;
					} else {
						do_write = true;
					}
				}
			}
			
			if (do_write) {
				bool do_update = false;
				int tries;
				obj_io io;
				io.len = ntotal;
				io.mode = OBJ_IO_WRITE;
				for (tries = 10; tries > 0; stries--) {
					if (extstore_write_request(storage, PAGE_BUCKET_COMPACT, PAGE_BUCKET_COMPACT, &io) == 0) {
						memcpy(io.buf, it, io.len);
						extstore_write(storage, &io);
						do_update = true;
						break;
					} else {
						usleep(1000);
					}
				}
				
				if (do_update) {
					if (it->refcount == 2) {
						hdr->page_version = io.page_version;
						hdr->page_id = io.page_id;
						hdr->offset = io.offset;
						rescues++;
					} else {
						lost++;
						// TODO: re-alloc and replace header
					}
				} else {
					lost++;
				}
			}
			
			do_item_remove(hdr_it);
		}
		
		item_unlock(hv);
		offset += ntotal;
		if (read_size - offset < sizeof(struct _stritem))
			break;
	}
	
	STATS_LOCK();
	stats.extstore_compact_lost += lost;
	stats.extstore_compact_rescues += rescues;
	stats.extstore_compact_skipped += skipped;
	STATS_UNLOCK();
	LOGGER_LOG(l, LOG_SYSEVENTS, LOGGER_COMPACT_READ_END, NULL, page_id, offset, rescues, lost, skipped);
}
```