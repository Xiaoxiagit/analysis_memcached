外存介绍文档
=============================
本文将开始介绍`memecached`的外存部分，从如下几个方面进行介绍:

1. 涉及的文档以及每个文档的含义。
2. 官方对外存的介绍。

## 1. 涉及的源文件
外存涉及的源文件主要有以下几个:

| 文件名称 | 文件作用 | 备注 | 其他 |
| ------- | ------ | ---- | ---- |
|`extstore.h/c` | 此文件主要用于定义管理外存的结构体 | 负责管理外存 | 暂无 |
|`storage.h/c` | 此文件主要用于定义外存写出和合并的两个线程 | 负责外存写出和合并 | 暂无 |
|`slab_automove_extstore.h/c` | 此文件用于定义在`slab_resign`线程中使用的外存分配的数据结构以及函数 | 外存中各`slab`重新分配的管理 | 本文档不做介绍 |

外存的方方面面基本就是依靠这三个文档进行管理和使用，后续的文档将详细介绍`extstore.h/c`和`storage.h/c`这四个文件中的内容。对于`slab_automove_extstore.h/c`文件，读者自行结合前面文档中描述的`slab_reassigned`线程进行阅读。

## 2. 官方介绍
官方对于外存的介绍有较为详细的介绍([官方文档](https://github.com/memcached/memcached.wiki.git))，本文也将大量采用官方文档中的描述进行介绍。本小节也算是对前面几个文档的一个总结。

外存对外提供的`settings`中设置参数主要有以下几个:

| 参数名 | 参数含义 | 参数默认取值 | 备注 |
|-------|---------|------------|-----|
|`ext_page_size`| 外存每页的大小 | 64M | 暂无 |
|`ext_wbuf_size`| 每次写出大小(写出缓冲区大小) | 8M | 为了提高写出效率，不能调小 |
|`ext_threads`| 读取/写出外存线程个数 | 1 | 为了降低读取延迟，可以适当调大 |
|`ext_item_size`| 写出内存的`item`的最小长度 | 512b | 不要调整过小，将会减低外存效率 |
|`ext_low_ttl`| 最小过期时间 | 0 | 设置合理值，有利于外存`page`的回收 |
|`ext_max_frag`|合并调整标识 | 0.8 | 当页面空闲度高于此值时，进行页面合并 |
|`ext_drop_unread`|合并调整标识 | false | 在页面合并过程中，是否丢弃长时间没有读取的`item` |
|`ext_compact_under`|合并调整设置| 总页面数/4 | 当空闲页面比例少于此值时，进行页面合并 |
|`ext_drop_under`|合并调整设置| 总页面数/4 | 当`ext_drop_unread`为`true`时，当空闲页面比例小于此值时，页面合并过程中将丢弃`COLD item`|
|`ext_recache_rate`|`item`返回`RAM`最小访问次数| 2000 | 当`item`1分钟被访问次数超过此值，将从外存返回到`RAM`中 |

### 2.1 高层次的描述
原文描述如下:

```
A single file is split into N logical pages of Y size (64M default).Write buffers (8M+) are used to store objects later flushed into pages.

IO threads are used to asynchronously flush write buffers and read items back.

Items are left in the hash table along with their keys, with small (24 byte as of this writing) headers detailing where data lives in flash.

The storage engine recycles pages by changing their version number.Item headers remember both the page ID and version number at the time the object was flushed. An attempted read with the wrong version will result in a miss.

The system is most useful if you have a breakdown of different item sizes: pools with a mix of small and large, or if you can break off a small pool of
machines with flash devices to store much larger items. Freeing up more memory on your small item pools can dramatically improve hitrates, or simply reduce costs overall.
```
从上述的描述可知，一个外存文件被分为多个`page`。`page`的每次读写的大小至少是一个`buffer`(8M)的大小。`IO`线程异步的将`buffer`写出到外存或者从外存读取`item`。外存对应的`item`链接`Hash`链表时，使用`key`对应的`Hash`值，其内容主要包括`page id/page version/offset`这三个值。外存通过改变`page version`来进行`page`回收，当`item`中的`page version`跟`page`(页面)中的`version`对不上时，证明`item`的空间已经被回收。

当你的系统中存在大量较小值与较大值时，外存的效果就比较明显。将较大值的`key`存放在外存上时，将提高内存使用率，提高命中率。

### 2.2 Technical Breakdown
```
This section is a detail on the architecture and tradeoffs of external storage.

Goals
Primarily: keeping "cache patterns" in mind,get the most out of a storage device by minimizing the accessses to it.

* Larger values (typically 1k+) can use flash. Small values stay in RAM.
* A single read to serve a single key.
* Asynchronous batched writes to drive.
* Main hash table is authoritative: miss/delete/overwrite must not use the drive.
* Wrting new items to cache must never block on the flash device.
	1. Items are evicted from the LRU tail in RAM if extstore writer lags.
* Forgetting/evicting data from storage must not use the drive.

Assumptions

Some assumptions about access patterns have to be made in order to utilize flash as a cache medium. Wrting is expensive (destructive to the drive), and caches typically have much higher churn rage than databases. Flash also increases the latency of each key fetched, which can make caching small values on flash ineffective compared a range fetch against a high end database.

* Logger TTL's for data that hits disk (and good reuse)
* Latency overhead for small items is high compared to benefit of storing them.
* Latency overhead for larger items is better than a miss (within reason).
* A minority of data is hot (highly accessed), with a long tail of colder data.
```

**Architecure**

```
A review of the main threads and data structures in memcached:
```

![architecture](https://github.com/whynotAC/analysis_memcached/blob/master/exstore/architecture.png)

```
THREADS

The listen thread accepts new connections, it then passes the socket to workers via writing a byte to a pipe. Each worker has its own "notifier pipe", which it receives events from via libevent polling. This mechanism is resued for extstore, allowing IO requests to pass to/from IO threads.

A client connection sticks to a worker thread for its lifetime.Own worker thread per CPU is ideal.

The LRU maintainer thread moves items inbetween sub-LRU's (hot|warm|cold|etc).It also makes decisions on when to schedule page moves, or LRU crawls.

The LRU cralwer reaps expired/invalid items, including items extstore invalidates.

Memory is divided into slab classes with fixed chunk sizes. Fixed size(1M) pages are assigned to each slab-class and divided into chunks as-needed. Over time, shifts in average item sizes or access patterns can "starve" a class.The page mover thread is able to safely reassign pages between slab classes to avoid strrvation.

Misc. threads: hash-table-expander,logger.These do not interact with extstore.

STRUCTURES

* Hash table is chain bucketed. "next" is embedded in item memory.
* LRU is doubly-linked, with net/prev embedded in item memory.
* Each slab class has its own LRU.
* Each LRU is split into HOT|WARM|COLD|TEMP.

Now, with extstore:
```
![add extstore architecture](https://github.com/whynotAC/analysis_memcached/blob/master/exstore/extstore_architecture.png)

```
THREADS

The storage thread is similar to the LRU maintainer (they may merge later).It exmines the LRU tails for each slab class.It requests a write buffer from extstore, CRC32's the item data, then hands the write buffer back to extstore.

The compaction thread targets pages ready for compaction.It reads the page data back from storage,walks the items within,and either throws them away or rewrites into a new page.See below for more detail.

Multiple IO threads exist which issue pread/pwrite/etc calls to the underlying storage on behalf of worker, storage, and compaction threads.Each IO thread has a simple stack queue with a mutex.

There is also an "extstore maintenance thread",which simply sorts page data for other threads.It may disapper and become an API call for the LRU maintainer.

STRUCTURES

Extstore has some of its own data structures.Mostly stats counters,and page data.

Pages on disk are (default 64M) subsections of a file or device.Each page has a small structure in memory.The structure in memory is used to avoid writing to flash when objects are deleted from a page.A page can be reclaimed once fully empty,so a page can be recycled without reading or writing back to it.

Extstore has write buffers which items are written into from the storage or compaction threads.When write buffers are full, a write will fail temporarily write the buffer is send to an IO thread.Once flushed, writes are accepted into the buffer again.This is used to rate limit writes to storage.
```
**How an item flows to storage**

![write item to extstore](https://github.com/whynotAC/analysis_memcached/blob/master/exstore/writeitemtoextstore.png)

```
* If all memory is exhausted while writes to storage are waiting, items will be evicted from the LRU tail in memory.IE: An item in slab class 10 waiting to be written to storage, will instead be evicted.Sets to cache must not block on storage.
```

**How an item is read from storage**

![read item from extstore](https://github.com/whynotAC/analysis_memcached/blob/master/exstore/readitemfromextstore.png)

```
* With multigets, many IO objects can be sent to the IO thread at teh same time.Typical flash devices are internally parallel, and can have similar latency for batched requests.
* Workers fill iovec's with response data while parsing each key in the request.For every item header,blank iovec's are added where the data would be.
* A temporary item is allocated from slab memory to hold the full item.
* If an item has become invlaid(page evicted, etc),the IO thread will record a miss back into the IO object before shipping back to the worker.
* On a hit,the holes are filled in the iovec with the temporary item.
* On a miss,the affected iovec entries are NULL'ed out, wiping the response.
* Temporary memory is freed at the end of the request.

Items read from storage have a chance of being recached into memory if they are read multiple times in less than a minute.This allows items which are only occasionally accessed to stay on storage.When they are recached into main memory,their flash entry is deleted.
```

**The lifetime of a stroage page**




